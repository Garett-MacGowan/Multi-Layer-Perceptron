Author: Garett MacGowan 
Student Number: 10197107 
Learning rate: 0.4
Learning rate is chosen as such through trial and error. 
The learning rate decreases over time proportional to the epoch. 

Momentum: 0.1
Momentum is chosen as such through trial and error. 
The momentum decreases over time proportional to the epoch. 

I have used a sigmoid activation function so that I can create a probability distribution for the class predictions. 
Sigmoid is also used so that the network is differentiable everywhere. 

Number of hidden layers: 1
There should not be too many hidden layers. This helps to avoid overfitting. 

Number of nodes in each hidden layer: 9
There should be the same number of nodes in the hidden layer as in input layer to allow for complex relations between all attributes. 

Number of nodes in output layer: 6
There should be the same number of nodes in the output layer as there are classes to prevent crosstalk. 

Regularization: 
I have used early stopping based on when my validation accuracy decreases as my main regularization approach. 
In addition, I am also only using one hidden layer, which helps to prevent data memorization. 

Preprocessing: 
I have removed the ID attribute from the data because it could give an unfair advantage to the algorithm. 
I have also normalized the attributes (between 0 and 1) so that no one attribute is given more importance over another. 

Training, validation, and testing split: 
The split follows 75% training, 10% validation, and 15% testing. 
Each set is statistically equivalent. That is, they have the same proportion of each class relative to their size. 

Confusion Matrix: 
[[10  1  0  0  0  0]
 [ 6  6  0  0  0  0]
 [ 3  0  0  0  0  0]
 [ 0  2  0  0  0  0]
 [ 0  1  0  0  0  1]
 [ 0  0  0  0  0  5]]

Precision for each class (ascending): 
[0.5263157894736842, 0.6, 0.0, 0.0, 0.0, 0.8333333333333334]

Recall for each class (ascending): 
[0.9090909090909091, 0.5, 0.0, 0.0, 0.0, 1.0]

Initial weights: 
[[ 0.72927342  0.32581939 -0.42491593  0.68128759  0.45271312  0.68913649
  -0.82251758 -0.04528245 -0.53870985]
 [ 0.60932102  0.62224589  0.70730346 -0.44165755 -0.89184128  0.95152714
   0.35240414  0.26143635  0.62856654]
 [ 0.52439979  0.51762471  0.97505082 -0.06823319 -0.69978973 -0.79333652
  -0.96610003  0.25340064 -0.48999326]
 [ 0.46747854  0.49698362  0.65727867  0.12422905  0.87911986 -0.95275049
   0.46233906  0.59919213 -0.48357445]
 [ 0.05578953  0.83178215  0.78265231 -0.46820072  0.3665294   0.35715018
   0.61366387 -0.33047974 -0.25395193]
 [-0.81750176  0.68594937 -0.76732289  0.44111675  0.57831466 -0.93140811
  -0.56433715 -0.67981631 -0.16102776]
 [-0.01812122  0.17077774 -0.69440428 -0.04546169  0.86165879  0.75127563
  -0.88328482  0.94175289  0.34025477]
 [ 0.66881251  0.18642579 -0.10855213 -0.92805593  0.68420545  0.31786901
  -0.02259589  0.5474111   0.81543262]
 [ 0.51688563 -0.49759349 -0.82437366 -0.29806806 -0.46346381 -0.3203421
  -0.41131883 -0.13037032 -0.97166961]]
[[ 0.27449174  0.25792732 -0.93101253 -0.07909188  0.3318102   0.33239992
  -0.49720831 -0.85872665 -0.81865551]
 [-0.96637868  0.22836164 -0.14437284  0.35846298 -0.92413244 -0.71301308
   0.81360947  0.60675696  0.37914167]
 [-0.20990902  0.53911512  0.93431642  0.41637264  0.71808155 -0.31067777
  -0.81468879  0.4180713   0.18898649]
 [ 0.63073938 -0.22262422  0.72375646 -0.33142252 -0.61444619  0.84929722
  -0.3042729  -0.22223464  0.49418953]
 [ 0.59513295  0.76226596 -0.79713172  0.57782561  0.19909943 -0.41111008
  -0.39846009  0.94314623  0.73464442]
 [ 0.50565879  0.53050685 -0.46487205  0.78054286  0.64592785  0.39513948
  -0.06256544  0.53074761  0.36628758]]

Final weights: 
[[ -2.38389104   2.60424688  -0.57621198   1.715062     2.58914514
   -1.7709361   -7.8737946    1.62975029  -1.25045329]
 [ -0.41147109   0.55435477   0.32583639  -0.05479603  -0.67912816
    0.0682801   -4.50936508   1.21306504   0.79642837]
 [-11.97868559  16.88901522   2.57712971   3.0845678   16.14255029
  -11.11329611 -15.51646458   1.30459695 -10.35500014]
 [  3.13110051  -4.76503204  -0.12205567  -0.29442137  -5.53397477
    1.43888737   3.09560582   1.68733774   4.00538332]
 [ -2.8819314    2.88821      0.59102998   0.50486761   2.29527744
   -1.99460703  -6.16722213   1.26186462  -0.88088229]
 [ -1.26179028   0.87549145  -0.62250767   0.48757692   0.63787605
   -0.56635097  -0.81717604  -0.30789907   0.15222718]
 [ -2.26160793   2.48417304  -0.59094975   0.85173629   2.7288243
   -0.96668042  -4.93826652   2.31150057  -0.21292885]
 [  5.56168171  -7.418047    -0.82242275  -2.50556395  -6.33956063
    3.84640143   3.04974059  -0.20626039   4.06807078]
 [  0.15962157   0.69468816  -0.1079192    0.09399875   0.38384866
   -0.6856838   -0.67897968   0.34103297  -1.79407664]]
[[-2.92717037  2.32282485  2.21335774 -0.41945169  2.98814891 -2.34309272
  -3.26984347 -1.15424837 -1.4362535 ]
 [-1.32666109  1.0854656  -0.36459894  0.73403525  0.25307621 -1.13842038
  -0.82879203  0.50768969 -0.00653643]
 [-1.42105272 -0.49852503 -0.13652302 -1.26226207 -0.16045371 -1.64923635
  -2.12942595 -1.06605013 -0.53613999]
 [ 0.12870784 -1.12977193 -1.70499897 -0.99410687 -2.53572957  0.42673086
  -0.65867102 -0.29884914 -0.6478238 ]
 [-0.39671433 -0.67846172 -1.84974324 -1.15091689 -1.16922648 -1.34613274
  -1.4853221  -0.58817897  0.09773179]
 [ 4.50353008 -3.53462575 -3.47783167 -2.12459126 -3.51458512  0.14611662
   3.48459428 -2.30270097 -0.71882365]]

