Learning rate: 0.2
Learning rate is chosen as such through trial and error 

Momentum: 0.1
Momentum is chosen as such through trial and error 

I have used a sigmoid activation function so that I can create a probability distribution for the class predictions 
Sigmoid is also used so that the network is differentiable everywhere 

Number of hidden layers: 1
There should not be too many hidden layers. This helps to avoid overfitting 

Number of nodes in each hidden layer: 9
There should be the same number of nodes in hidden layer as in input layer to allow for complex relations between all attributes 

Number of nodes in output layer: 6
There should be the same number of nodes in the output layer as there are classes to prevent crosstalk 

Regularization: 
I have used early stopping based on when my validation accuracy decreases as my main regularization approach 

Preprocessing: 
I have removed the ID attribute from the data because it could give an unfair advantage to the algorithm 
I have also normalized the attributes (between 0 and 1) so that no one attribute is given more importance over another 

Training, validation, and testing split 
The split follows 75% training, 10% validation, and 15% testing 
Each set is statistically equivalent. That is, they have the same proportion of each class relative to their size 
Initial weights: 
[[0.04222236 0.23937957 0.12924311 0.31212834 0.58727064 0.21018238
  0.22066494 0.71041039 0.93907841]
 [0.07234451 0.51922099 0.6326553  0.21353319 0.35274378 0.41361728
  0.59405113 0.20528072 0.6299418 ]
 [0.61902538 0.14607912 0.19720993 0.5788506  0.94239163 0.21010267
  0.02218573 0.74109053 0.81597721]
 [0.58835781 0.43912211 0.04944117 0.37752167 0.2096661  0.20979015
  0.28503328 0.58195445 0.39426615]
 [0.70942937 0.18828001 0.65006739 0.74805439 0.48186123 0.91736513
  0.92153676 0.86341873 0.8555805 ]
 [0.07647511 0.70839012 0.13486013 0.48988757 0.30482528 0.41784035
  0.18330331 0.04978012 0.89570717]
 [0.36016416 0.69444778 0.21588405 0.86307641 0.56943255 0.64736839
  0.73588847 0.16954724 0.46457732]
 [0.49720087 0.92996927 0.2574301  0.06656906 0.49628095 0.57945904
  0.42265472 0.99645931 0.37291312]
 [0.46350325 0.74266962 0.38617151 0.06399885 0.93188893 0.40891964
  0.22653364 0.83868714 0.14205094]]
[[0.7997117  0.15904087 0.71581316 0.31593626 0.24723995 0.021086
  0.26440009 0.89854977 0.09651703]
 [0.61129183 0.91603732 0.65032772 0.39023048 0.26622851 0.3607582
  0.25178414 0.33132162 0.40004908]
 [0.38506532 0.32622194 0.86911643 0.51921292 0.35431041 0.87329443
  0.28340147 0.80865178 0.93615385]
 [0.51220119 0.84039116 0.07064916 0.53239634 0.54683873 0.96422388
  0.44382455 0.42485726 0.73010542]
 [0.91972177 0.92645054 0.85396503 0.26941505 0.36744211 0.51408948
  0.29761085 0.49833616 0.5344188 ]
 [0.98878759 0.55146919 0.40708865 0.86291887 0.00225004 0.55905761
  0.89519903 0.89027133 0.21167697]]

Final weights: 
[[-0.62338437 -0.42622716 -0.53636361 -0.35347839 -0.07833608 -0.45542434
  -0.44494178  0.04480367  0.27347168]
 [-0.65583637 -0.20895988 -0.09552558 -0.51464768 -0.3754371  -0.3145636
  -0.13412975 -0.52290016 -0.09823908]
 [-0.53951963 -1.01246588 -0.96133507 -0.57969441 -0.21615338 -0.94844233
  -1.13635928 -0.41745448 -0.3425678 ]
 [-0.52024364 -0.66947933 -1.05916027 -0.73107977 -0.89893534 -0.89881129
  -0.82356816 -0.52664699 -0.71433529]
 [-0.77291804 -1.29406741 -0.83228003 -0.73429303 -1.00048618 -0.56498228
  -0.56081066 -0.61892869 -0.62676691]
 [-0.84545497 -0.21353997 -0.78706996 -0.43204251 -0.61710481 -0.50408973
  -0.73862678 -0.87214997 -0.02622292]
 [-1.20937839 -0.87509477 -1.35365851 -0.70646614 -1.00011001 -0.92217416
  -0.83365408 -1.39999531 -1.10496523]
 [-0.61976469 -0.1869963  -0.85953547 -1.05039651 -0.62068461 -0.53750653
  -0.69431085 -0.12050626 -0.74405244]
 [-0.76432631 -0.48515995 -0.84165806 -1.16383072 -0.29594064 -0.81890993
  -1.00129593 -0.38914243 -1.08577863]]
[[ 0.80754582 -0.94893743  1.25296749  0.74941219  0.2100381   2.16985943
   1.01574093  2.71424293  1.39027704]
 [ 0.61766215 -0.20979631  1.19468574  0.82634381  0.22767855  2.52727535
   1.01230203  2.14625917  1.69611494]
 [ 0.39187525 -0.80909301  1.43482422  0.97783442  0.31443322  3.10306585
   1.07875278  2.65009351  2.26238831]
 [ 0.51833046 -0.29974921  0.63216176  0.9863021   0.50723472  3.18097147
   1.23168339  2.25668996  2.04851151]
 [ 0.92580183 -0.22308623  1.41424488  0.72299839  0.32816499  2.72944603
   1.08137101  2.34100029  1.85586521]
 [ 0.99544558 -0.59645796  0.96978909  1.31766086 -0.03727504  2.77846956
   1.68290085  2.73825789  1.53659315]]

